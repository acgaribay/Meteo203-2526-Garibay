{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c573fe3-deda-4ef3-8364-9f53531d918d",
   "metadata": {},
   "source": [
    "# Lesson 06. Introduction to Patterns in Multivariate Data\n",
    "\n",
    "## Introduction\n",
    "In this exercise, we will explore how Principal Component Analysis (PCA) — also known in climate science as Empirical Orthogonal Function (EOF) analysis — can be used to uncover dominant patterns of variability in sea surface temperature (SST).\n",
    "\n",
    "Using the Extended Reconstructed Sea Surface Temperature (ERSSTv6) dataset, we will:\n",
    "\n",
    "1. Compute SST anomalies relative to a climatological baseline.\n",
    "2. Construct the Niño 3.4 Index, a widely used measure of the El Niño–Southern Oscillation (ENSO).\n",
    "3. Apply PCA to the tropical Pacific SST field and interpret the resulting modes (EOFs and PCs).\n",
    "\n",
    "By the end of this lesson, we should be able to:\n",
    "- Describe how PCA decomposes a large spatiotemporal dataset into spatial patterns and temporal modes.\n",
    "- Recognize the seasonal cycle and ENSO as the first two leading EOFs of tropical Pacific SST.\n",
    "- Compare a physically defined ENSO index (Niño 3.4) with a statistically derived one (PC 2).\n",
    "\n",
    "\n",
    "#### Acknowledgements and AI Disclaimer \n",
    "This lesson was adapted from the [Karen L. Smith](https://kls2177.github.io/)'s book on [Climate and Geophysical Data Analysis](https://kls2177.github.io/Climate-and-Geophysical-Data-Analysis/chapters/index.html), in particular, the chapter on [Patterns in Multivariate Data](https://kls2177.github.io/Climate-and-Geophysical-Data-Analysis/chapters/Week7/pca.html). Data for this lecture is downloaded and complied from [NOAA's Extended Reconstructed Sea Surface Temperature (ERSST)](https://www.ncei.noaa.gov/products/extended-reconstructed-sst). \n",
    "\n",
    "A set of [downloader](preprocessor_download-sst.sh) and [combiner scripts](preprocessor_combine-nc.ipynb) are provided in this repository. For your convenience, I have compiled the data (1950-2024) [in this link](https://drive.google.com/file/d/1GIY4GuzoVK7qTlhfMywEMS7ghmywiJ_7/view?usp=sharing). Download this and store the data in the same folder as this notebook.\n",
    "\n",
    "The material has been updated and restructured for Meteo 203 (Methods of Analytical Meteorology & Oceanography) with the assistance of ChatGPT for code modernization, annotation, and formatting.\n",
    "\n",
    "All scientific content, computations, and instructional revisions have been reviewed and verified by BBR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cbc73f-a834-4542-a245-bfd2477a7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case packages haven't been installed, uncomment the snippet below, and run the cell.\n",
    "# !conda install -c conda-forge h5py xarray netCDF4 --name meteo203 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f729c4c-c41b-40f9-8107-4a4cf2b4c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from cartopy.geodesic import Geodesic\n",
    "from shapely.geometry import box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cd2f8-5e0c-4a45-a66c-fe7782b82852",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Part 1. Open the data using xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3dad2-56cb-42c0-a50a-c758bffed284",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'ersst.v6.195001_202412.nc'\n",
    "ds = xr.open_dataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a654fa-aa05-4e44-b379-144473bb48bf",
   "metadata": {},
   "source": [
    "#### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b24643-f494-4289-bafb-bbd97a26757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43970f2d-ae76-46f3-936f-7b0665a5b417",
   "metadata": {},
   "source": [
    "We'll be selecting `sst` data for the first level using the snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75694e-c453-46c4-acc5-b11108bb5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = ds['sst'].isel(lev=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e2030-5c8b-4a49-bba5-e47e52630b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1eadcc-4e10-4107-b810-4fe6cc894f52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Part 2. Calculate climatologies.\n",
    "\n",
    "The data we have is for 1950 to 2024. Let's calculate for climatological normals from 1950 to 1979 by calculating the mean according to the `time` dimension. \n",
    "\n",
    "We first get the time period using `.sel(time=slice(\"1950\", \"1979\"))`, and then the mean in the time axis using `.mean(dim=\"time\")`. This can be done in one line as provided in the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f723b9c-f207-4ce8-ab73-38837a7a55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_clim = sst.sel(time=slice(\"1950\", \"1979\")).mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b691f6b-fd91-4550-b955-fca36f36f156",
   "metadata": {},
   "source": [
    "We can now plot the climatologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c2160-d12e-4b51-a458-ce15e034c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sst_clim.plot(cmap='RdBu_r', vmin=0, vmax=30)\n",
    "plt.title(\"ERSSTv6 Sea Surface Temperature Climatology (1950-1979)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97995cf4-4204-4e7a-ad20-d6f90069e828",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 3. Calculate annual means.\n",
    "\n",
    "The data is stored in monthly periods (`time: 900`). We can index and select according to month, or we can do this according to year. For this section let's slice according to year (`.sel(time=\"2024\")`) giving us 12 months in a dataframe.  We can then proceed to calculate the annual mean, again according to `time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06c438-10d4-47c6-aa45-59c09fde97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SST for one year, and then calculate the mean.\n",
    "sst_2024 = sst.sel(time=\"2024\").mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd63d03-0340-4b07-99fe-39dfc0a6bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sst_2024.plot(cmap='RdBu_r', vmin=0, vmax=30)\n",
    "plt.title(\"ERSSTv6 Annual Mean Sea Surface Temperature (2024)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c75fa-e6bf-4e60-92b9-cbdddf67217b",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 4. Calculate anomalies.\n",
    "\n",
    "By itself the annual means do not look much. By qualitative comparison, the two plots above look similar. To see the differences of a certain year compared to the climatology, we can calculate the *anomalies* by subtracting the climatology (1950-1979) from the annual mean. Notice how the colorbar is now centered on zero, depending on how we set the `vmin` and `vmax`.\n",
    "\n",
    "In the map below, notice where the SST is warmer than the climatological normals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e668a3-0102-4ee3-bc13-fe5bf79e604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_anom_2024 = sst_2024 - sst_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b4e1c-633f-42db-a7c1-d123035dedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sst_anom_2024.plot(cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "plt.title(\"SST Anomalies (2024 relative to 1950-1979 climatology)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4449227a-6350-4223-9a86-f83f2d789ccd",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 5. Calculate anomalies for the 1997 ENSO onset.\n",
    "\n",
    "The 1997-1998 ENSO was considered [one of the strongest on record](https://www.pmel.noaa.gov/pubs/outstand/mcph2029/text.shtml). Let's try to take a look at the annual SST anomalies for 1997.\n",
    "\n",
    "First let's calculate and plot the annual average SSTs for 1997."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0678f1-624f-4c8a-9ae3-c470e1701215",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_1997 = sst.sel(time=\"1997\").mean(dim='time')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sst_1997.plot(cmap='RdBu_r', vmin=0, vmax=30)\n",
    "plt.title(\"ERSSTv6 Annual Mean Sea Surface Temperature (1997)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b4a34-6612-4d8e-ba4a-420d3eb69f19",
   "metadata": {},
   "source": [
    "Now let's calculate for the anomalies and then plot. \n",
    "\n",
    "How does the map above (annual mean) compare with the map below (anomalies)? Notice the extension of the warm tongue in South America. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936a338-7935-4328-9c60-6f95669a57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SST for one year\n",
    "sst_anom_1997 = sst_1997 - sst_clim\n",
    "plt.figure(figsize=(12,5))\n",
    "sst_anom_1997.plot(cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "plt.title(\"SST Anomalies (1997 relative to 1950-1979 climatology)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737e28a-c4e2-4571-9568-d0022495aa0b",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 6. Plot in cartopy to contextualize\n",
    "\n",
    "The maps above are simple array plots. We can plot them with cartopy so we have contextual information (i.e. country boundaries). \n",
    "\n",
    "Hint: try changing the `central_longitude` input, what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dae1bc-20d0-49bc-8216-6a2dc4539062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select and compute anomaly\n",
    "sst_1997 = sst.sel(time=\"1997\").mean(dim=\"time\")\n",
    "sst_anom_1997 = sst_1997 - sst_clim\n",
    "\n",
    "# Set up figure with Cartopy\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "proj = ccrs.PlateCarree(central_longitude=0)\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "# Add map features\n",
    "ax.coastlines(resolution=\"110m\", linewidth=1)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n",
    "ax.set_global()\n",
    "ax.gridlines(draw_labels=True, linewidth=0.3, color=\"gray\", alpha=0.5)\n",
    "\n",
    "# Plot SST anomalies\n",
    "pcm = sst_anom_1997.plot.pcolormesh(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-2, vmax=2,\n",
    "    add_colorbar=True,\n",
    "    add_labels=False\n",
    ")\n",
    "\n",
    "# Add title\n",
    "plt.title(\"SST Anomalies (1997 vs 1950-1979 climatology)\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a95d6-b9a9-46b8-9143-98e85537055f",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 7. Calculating the Niño3.4 Index.\n",
    "\n",
    "In this sectopm we are going to construct the ENSO index. First, we will construct it following the [Niño 3.4 Index](http://www.cgd.ucar.edu/cas/catalog/climind/TNI_N34/index.html#Sec5) definition. The Niño3.4 Index is a commonly used metric of ENSO variability. The recipe for calculating it is:\n",
    "\n",
    "1. Compute area averaged total SST from Niño3.4 region (5N-5S, 170W-120W).\n",
    "2. Compute monthly climatology (1950-1979) for area averaged total SST from Niño 3.4 region\n",
    "3. Subtract climatology from area averaged total SST time series to obtain anomalies.\n",
    "4. Smooth the anomalies with a 5-month running mean.\n",
    "5. Standardize the smoothed Niño3.4 by its standard deviation over the climatological period 1950-1979.\n",
    "\n",
    "But first, let's plot the `sst_1997` maps from above along with the  Niño 3.4 boundaries. We can plot the [Niño 3.4 boundaries](https://www.ncei.noaa.gov/access/monitoring/enso/sst) using the `n34_box` variable and `add_geometries` in the script below. Since we have already calculated `sst_anom_1997` in a cell above, no need to recalculate here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11326504-7fda-4a72-9113-7894de6ea581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure with Cartopy\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "proj = ccrs.PlateCarree(central_longitude=180)\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "# Add map features\n",
    "ax.coastlines(resolution=\"110m\", linewidth=1)\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n",
    "ax.set_global()\n",
    "ax.gridlines(draw_labels=True, linewidth=0.3, color=\"gray\", alpha=0.5)\n",
    "\n",
    "# Plot SST anomalies\n",
    "pcm = sst_anom_1997.plot.pcolormesh(\n",
    "    ax=ax,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-2, vmax=2,\n",
    "    add_colorbar=True,\n",
    "    add_labels=False\n",
    ")\n",
    "\n",
    "# Define Nino 3.4 box boundaries\n",
    "lon_min, lon_max = 190, 240   # 170°W–120°W in 0–360° convention\n",
    "lat_min, lat_max = -5, 5\n",
    "\n",
    "# Create a rectangular polygon\n",
    "n34_box = box(lon_min, lat_min, lon_max, lat_max)\n",
    "\n",
    "# Add it to the map\n",
    "ax.add_geometries(\n",
    "    [n34_box],\n",
    "    crs=ccrs.PlateCarree(),\n",
    "    facecolor=\"none\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\"\n",
    ")\n",
    "\n",
    "\n",
    "# Add title\n",
    "plt.title(\"SST Anomalies (1997 vs 1950-1979 climatology) with Niño 3.4 Boundaries\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff67f9a-f805-4974-88fe-d36b7f95a138",
   "metadata": {},
   "source": [
    "At this point let's now calculate the SST anomalies in the Niño 3.4 region. We can use xarray's [`sel`](https://docs.xarray.dev/en/latest/generated/xarray.DataArray.sel.html) and then slice according to `lat` and `lon`.  Afterwards, we can take the mean for the sliced box using `.mean(dim=[\"lat, \"lon\"])`.\n",
    "\n",
    "Notice in the script below we directly subtracted the slice from the climatology. If the xarray dataframe is constructed properly, the mathematical operations will respect the geography of the individual dataframes (i.e. we are subtracting from the same slices). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda8eda-32e8-4c2b-be12-fe0efdcce7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sst_1997_monthly = sst.sel(time=\"1997\")\n",
    "sst_anom_n34 = sst.sel(lat=slice(-5, 5), lon=slice(190, 240)) - sst_clim\n",
    "\n",
    "# Take the mean over both lat and lon for each time step\n",
    "nino34 = sst_anom_n34.mean(dim=[\"lat\", \"lon\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752930c-f2fc-4677-9821-67d9d8ee33de",
   "metadata": {},
   "source": [
    "At this point, `nino34` should be a time-series array of 900 timesteps. Question: what do these timesteps represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b139d-1de5-4bb5-947a-6d424f920878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the nino34 dataframe\n",
    "nino34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b2941-af9b-4aa1-876d-678401667545",
   "metadata": {},
   "source": [
    "[The Niño 3.4 index typically uses a 5-month running mean](https://climatedataguide.ucar.edu/climate-data/nino-sst-indices-nino-12-3-34-4-oni-and-tni), and El Niño or La  Niña events are defined when the  Niño 3.4 SSTs exceed +/- 0.4C for a period of six months or more. Let's now calculate for the 5-month running mean using xarray's [`rolling`](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.rolling.html) windows, and then let's calculate the `.mean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a7fb7-7950-4a69-91b1-f6bd07c288dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply 5-month centered rolling mean\n",
    "nino34_smooth = nino34.rolling(time=5, center=True).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cddbb-5508-477f-abf2-e9c0bc1ee390",
   "metadata": {},
   "source": [
    "Since the data spans many years (1950-1979), we need to first normalize and then  standardize; in our lecture, we called this the *standardized anomalies*. For the `base_period` 1950 to 1979, let's first calculate the mean for the period (`mean_base`), and then the standard deviation (`std_base`). Afterwards, let's calculate the standardized anomalies by subtracting the mean from the smoothed data, and then dividing by the standard deviation for the base period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdef05f-cb44-46e1-8e76-b2a4540bacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and std from baseline (1950–1979)\n",
    "base_period = slice(\"1950\", \"1979\")\n",
    "mean_base = nino34_smooth.sel(time=base_period).mean()\n",
    "std_base  = nino34_smooth.sel(time=base_period).std()\n",
    "\n",
    "# Standardize\n",
    "nino34_std = (nino34_smooth - mean_base) / std_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb95872-26e4-4bcc-9464-d51971585e8d",
   "metadata": {},
   "source": [
    "At this point we can plot the `nino34_std`, which is the standardized anomalies for the 5-month running mean. [The Oceanic Niño Index or ONI](https://www.ncei.noaa.gov/access/monitoring/enso/sst#oni) defines warm and cold phases as a minimum of five consecutive 3-month running averages of SST anomalies in the Niño 3.4 region surpassing a threshold of +/- 0.5°C, respectively. \n",
    "\n",
    "We can plot these thresholds using matplotlib's [`axhline`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axhline.html). We can also color the under the time-series whenever they exceed 0 in the positive or negative using [`fill_between`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.fill_between.html). All of this code is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4bb261-7195-4cb8-8e53-424117eaa46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "nino34_std.plot(color=\"steelblue\", lw=1.5, label=\"Niño 3.4 (5-month mean)\")\n",
    "plt.axhline(0.5, color=\"r\", ls=\"--\", lw=1)\n",
    "plt.axhline(-0.5, color=\"b\", ls=\"--\", lw=1)\n",
    "plt.fill_between(nino34_std[\"time\"], 0, nino34_std,\n",
    "                 where=nino34_std > 0, color=\"red\", alpha=0.3)\n",
    "plt.fill_between(nino34_std[\"time\"], 0, nino34_std,\n",
    "                 where=nino34_std < 0, color=\"blue\", alpha=0.3)\n",
    "plt.title(\"Standardized Niño 3.4 Index (5-month running mean, base 1950–1979)\")\n",
    "plt.ylabel(\"Standardized SST Anomaly (σ)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859bdca-3db0-43a6-9a1f-368e9b37b188",
   "metadata": {},
   "source": [
    "Congratulations! You have plotted the Nino 3.4 index. \n",
    "\n",
    "Based on the plot above, is the 1997-1998 still the strongest El Niño event? If you want, you can try calculating and plotting other El Niño events in additional cells below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6eff51-1c86-43fb-a5db-374e1acb305c",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 8. PCA of Tropical Pacific SST: Setting up the Problem\n",
    "\n",
    "Now we will perform a principal component analysis (PCA) on the tropical Pacific SST. Our goal is to see if we can recreate the Niño 3.4 Index time series above through PCA. \n",
    "\n",
    "Before we do the PCA, we will take a look at the spatial structure of the data. Let’s pick a larger region so that we can more easily see what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a1e12-84dd-42ff-8d13-640a2f0d3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_pac = sst.sel(time=slice(\"1950\", \"2020\"),\n",
    "                  lat=slice(-30, 30),\n",
    "                  lon=slice(120, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc22c1-9ef0-475c-ae68-fb316c3adf04",
   "metadata": {},
   "source": [
    "The output of PCA is a set of pairs of spatial patterns (EOFs) and time series (PCs). The size of the set depends on the size of the original data. The pairs are ordered in terms of variance explained, i.e. the first pair explains the largest fraction of variance in the data, the second pair explains the second largest fraction of variance, and so on.\n",
    "\n",
    "If we leave the seasonal cycle in our data, the seasonal cycle will likely emerge as the largest source of variance. Let’s see if this is what we get.\n",
    "\n",
    "First, we will compute an anomaly. We will NOT subtract a monthly climatology (we want to see the seasonal cycle emerge from our analysis) - instead just subtract the time mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e543b96-9171-40d1-ad27-e7d6b7edfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Remove only the time mean\n",
    "ssta_pac = sst_pac - sst_pac.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb6887-6298-4946-bbf7-80a4a444b359",
   "metadata": {},
   "source": [
    "To visualize these anomalies, we can plot the data on a map by slicing just one one element in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7faa9-deb8-4145-b1ca-5cbd000a4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.pcolormesh(ssta_pac[0],cmap = \"RdBu_r\", )\n",
    "plt.clim(-4,4)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fcfe24-6b91-4915-a461-12754c12bb41",
   "metadata": {},
   "source": [
    "If we do remove the monthly climatology, how does the above anomaly plot change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5ba18-69ca-465d-afd2-d5d3f259e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Remove overall time mean — keep seasonal cycle\n",
    "ssta_pac = sst_pac - sst_pac.mean(dim=\"time\")\n",
    "\n",
    "# (2) Remove monthly climatology — remove seasonal cycle\n",
    "sst_clim_monthly = sst_pac.groupby(\"time.month\").mean(dim=\"time\")\n",
    "ssta_pac_noseason = sst_pac.groupby(\"time.month\") - sst_clim_monthly\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "ssta_pac.isel(time=0).plot(cmap=\"RdBu_r\", vmin=-4, vmax=4)\n",
    "plt.title(\"(a) SST Anomaly with Time Mean Removed\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "ssta_pac_noseason.isel(time=0).plot(cmap=\"RdBu_r\", vmin=-4, vmax=4)\n",
    "plt.title(\"(b) SST Anomaly with Monthly Climatology Removed\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257f396-c28d-465d-80ef-b1d3ff57688d",
   "metadata": {},
   "source": [
    "We see some similar features between the two plots, but we also see that the warm southern hemisphere and the cold northern hemisphere is reduced, suggesting that this part of the pattern is associated with the seasonal cycle.\n",
    "\n",
    "When we subtract the time mean, we remove the global offset but the repeating annual cycle remains.\n",
    "\n",
    "When we subtract the monthly climatology, we remove the seasonal cycle itself — leaving behind year-to-year anomalies like El Niño and La Niña.\n",
    "This step is crucial because PCA identifies dominant patterns of variance, and if we don’t remove the seasonal cycle, it will dominate the first EOF.\n",
    "\n",
    "PCA should identify sources of variance, so a good place to start to explore the variance in our data is to plot the standard deviation for each grid point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a1574-7c2a-4476-90aa-efdae974acf0",
   "metadata": {},
   "source": [
    "We can plot the standard deviation on a map. \n",
    "\n",
    "When we only remove the overall mean, the largest SST variability appears in the mid-latitudes — that’s mostly the seasonal cycle.\n",
    "\n",
    "But when we remove the monthly climatology, the remaining variability shifts to the tropical Pacific, where ENSO dominates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5282ab2-238c-4dce-b63f-3ce59d5f708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spatial standard deviation maps\n",
    "ssta_pac_std = ssta_pac.std(dim=\"time\")\n",
    "ssta_pac_std_noseason = ssta_pac_noseason.std(dim=\"time\")\n",
    "\n",
    "# Visualize side by side\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "# (a) Time-mean removed (seasonal cycle retained)\n",
    "plt.subplot(1,2,1)\n",
    "ssta_pac_std.plot(cmap=\"Reds\", vmin=0, vmax=5, add_colorbar=True)\n",
    "plt.title(\"(a) STDEV of SST Anomaly (Time Mean Removed)\")\n",
    "\n",
    "# (b) Monthly climatology removed (seasonal cycle removed)\n",
    "plt.subplot(1,2,2)\n",
    "ssta_pac_std_noseason.plot(cmap=\"Reds\", vmin=0, vmax=1.5, add_colorbar=True)\n",
    "plt.title(\"(b) STDEV of SST Anomaly (Monthly Climatology Removed)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c21138-0284-42f8-9f88-316dd434b560",
   "metadata": {},
   "source": [
    "We can then also plot this in a cartopy map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f7b84-a753-4140-afd2-044b9b75e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.PlateCarree(central_longitude=180)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18,5), subplot_kw={'projection': proj})\n",
    "\n",
    "for ax, field, title, vmax in zip(\n",
    "    axs,\n",
    "    [ssta_pac_std, ssta_pac_std_noseason],\n",
    "    [\"(a) Time Mean Removed\", \"(b) Monthly Climatology Removed\"],\n",
    "    [5, 1.5]\n",
    "):\n",
    "    field.plot.pcolormesh(\n",
    "        ax=ax, transform=ccrs.PlateCarree(),\n",
    "        cmap=\"Reds\", vmin=0, vmax=vmax,\n",
    "        add_colorbar=True, add_labels=False\n",
    "    )\n",
    "    ax.coastlines()\n",
    "    ax.set_global()\n",
    "    ax.set_title(f\"STDEV of SST Anomaly {title}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568b8ff-ec45-4db9-a1c4-e18dd4d248ca",
   "metadata": {},
   "source": [
    "### Part 9. PCA: Step-by-step\n",
    "\n",
    "In this section we will calculate the PCA using the provided steps below. For a very brief overview, you can take a look at a brief summary of calculating the PCA [here](https://medium.com/analytics-vidhya/understanding-principle-component-analysis-pca-step-by-step-e7a4bb4031d9). Take note that the aforementioned article calculates PCA for 2 dimensions, while we will be calculating for 3 dimensions (which we will be reducing to 2). \n",
    "\n",
    "In summary, the steps are as follows:\n",
    "1. Clean the data by filling in missing values\n",
    "2. Standardize the data\n",
    "3. Convert from 3D to 2D\n",
    "4. Calculate the [covariance matrix](https://www.itl.nist.gov/div898/handbook/pmc/section5/pmc541.htm)\n",
    "5. Perform [eigenanalysis](https://online.stat.psu.edu/stat505/lesson/4/4.5) for the covariance matrix\n",
    "6. Extract and standardize the first two [Empirical Orthogonal Functions or EOF](https://climatedataguide.ucar.edu/climate-tools/empirical-orthogonal-function-eof-analysis-and-rotated-eof-analysis)\n",
    "7. Plot EOF1 (seasonal cycle), plot EOF2 (what other pattern emerges)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8901c460-7a18-4e59-9030-304f7916591a",
   "metadata": {},
   "source": [
    "#### Step 1: Fill in missing values\n",
    "This step is important since some matrix calculations will fail if some values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98ed54-da0a-4935-be38-d7acca2a9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ssta_pac.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505e9a7-a041-4a37-b14f-e493eaa73550",
   "metadata": {},
   "source": [
    "#### Step 2: Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b5bc8-33f6-4539-adb6-6d111522e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (a - a.mean()) / a.std()\n",
    "print(a.mean(), a.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b81cd-f0b9-4f4a-9407-3d9387bdf460",
   "metadata": {},
   "source": [
    "#### Step 3: Convert 3D array to 2D matrix\n",
    "\n",
    "The next step is to convert our 3D array into a 2D matrix, so that we can perform matrix operations. We do this by combining all the spatial dimensions together.\n",
    "\n",
    "First, let's check the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7b3f3-501c-45d3-92dd-d972b223a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b3968-3c33-40d2-a49f-42e199843397",
   "metadata": {},
   "source": [
    "We have a 3-D array (time, latitude, longitude). We need to convert it to 2-D.  So, we combine the two spatial dimensions (latitude and longitude) into one by reshaping the arrays. Think of this as compressing or squeezing in the multidimensional data (time, lat, lon) into two dimensions (time, latlon).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe98d9-f887-4376-8b37-39297b923974",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape the array to have one time dimension, one space dimension\n",
    "\n",
    "Nt, Ny, Nx = a.sizes[\"time\"], a.sizes[\"lat\"], a.sizes[\"lon\"]\n",
    "A = a.values.reshape(Nt, Ny * Nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe641a-0a65-495a-b3a8-b40eee2bd9da",
   "metadata": {},
   "source": [
    "Check the shape of the combined data (`A.shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff74687-87bf-403b-8218-cdf5c46834a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d07f479-fd58-4937-955a-788dc7965366",
   "metadata": {},
   "source": [
    "#### Step 4: Calculate covariance matrix\n",
    "Now, we can calculate the [covariance matrix](https://numpy.org/doc/2.3/reference/generated/numpy.cov.html). Since our data is standardized, we will actually be computing the correlation matrix.\n",
    "\n",
    "Similar to the correlation matrix in Exercise 5, we are calculating for how similar (or different) are the SST observations in pairs of time and combined space. We won't be plotting the heatmap this time since this will be a correlation matrix for 2,821 pairs of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56f2fc-4758-4b92-a4db-ed1b04348999",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.cov(A, rowvar=False)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c6b12-6d4a-451f-8c95-73ebd2ba6523",
   "metadata": {},
   "source": [
    "#### Step 5: Perform eigenanalysis of covariance matrix\n",
    "\n",
    "Eigenanalysis finds the principal directions of *variability* in the covariance matrix - the axes along which the data vary the most.\n",
    "\n",
    "In PCA, these directions are called the [*eigenvectors* (the spatial patterns or EOFs)](https://math.libretexts.org/Bookshelves/Linear_Algebra/A_First_Course_in_Linear_Algebra_(Kuttler)/07%3A_Spectral_Theory/7.01%3A_Eigenvalues_and_Eigenvectors_of_a_Matrix). Their corresponding *eigenvalues* tell us how much variance each mode explains.\n",
    "\n",
    "In other words, Eigenvectors show the main directions of variability (the patterns), and eigenvalues tell how important each one is.\n",
    "\n",
    "We can calculate these using [`np.linalg.eig()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.eig.html#scipy.linalg.eig), where the expected outputs are the Eigenvalues and the Eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6559828-fee7-4821-b260-4ca1f4194b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals, eigvecs = np.linalg.eig(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb93d98-6b91-41d8-81b0-f253acebbadc",
   "metadata": {},
   "source": [
    "The output of the eigenanalysis is a set of spatial patterns (EOFs). For the code above,\n",
    "\n",
    "- `eigvals` → a list of numbers (one per mode) that tell us how much variance each eigenvector explains.\n",
    "    - Larger eigenvalues → more important patterns.\n",
    "\n",
    "- `eigvecs` → a set of vectors that show the directions or patterns of variability (in PCA, these become the EOFs).\n",
    "    - Each column of `eigvecs` corresponds to one spatial pattern (one EOF).\n",
    "    - Together with the time series they produce (the PCs), they describe how the data varies in space and time.\n",
    "\n",
    "In short: `eigvals` tell us how much, and `eigvecs` tell us where and how the data vary.\n",
    "\n",
    "We can try printing the `eigvals` array to show how important each principal component (PC) is. The magnitude of each element shows the *relative importance* of each PC (i.e. the first element corresponds to PC 1 (the dominant mode), the second to PC 2, and so on.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a9e14-62f0-4744-9cae-816a2b2c56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fecd47-d188-4bf2-8ea4-d91b04e26840",
   "metadata": {},
   "source": [
    "The companion array `eigvecs` contains the spatial patterns (directions) associated with each PC.\n",
    "\n",
    "Each **column** of `eigvecs` represents one eigenvector — the **pattern of weights** that defines how different grid points vary together to form that PC. \n",
    "\n",
    "Check the shape of `eigvecs` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d60404-3017-476a-b137-757ef7dc0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99eb04c-6912-4b6f-b1b2-5d084b3ebc17",
   "metadata": {},
   "source": [
    "The eigenvectors (`eigvecs`) are returned by NumPy as columns of a 2-D array, where each column corresponds to one principal component (PC), and each row corresponds to one grid point (a specific latitude–longitude location) in our dataset.\n",
    "\n",
    "When we prepared our data for PCA, we *flattened the spatial dimensions* (lat × lon) into a single “space” dimension —\n",
    "so each grid cell’s SST time series became *one row* in our covariance matrix.\n",
    "\n",
    "In the next step, we’ll reshape these eigenvectors back into latitude–longitude maps to visualize the EOF spatial patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0a38e-cc60-4e31-ac44-ee31ddb9a502",
   "metadata": {},
   "source": [
    "#### Step 6: Extract and standardize the first two EOFs and PCs\n",
    "\n",
    "The eigenvectors from the covariance matrix can also be called Empirical Orthogonal Functions (EOFs) in climate science.\n",
    "\n",
    "Each EOF represents a spatial pattern that explains a particular fraction of variance in the dataset —\n",
    "in our case, patterns of SST variability across the tropical Pacific.\n",
    "- EOF 1 corresponds to the spatial pattern of the dominant mode (usually the seasonal cycle).\n",
    "- EOF 2 often represents the next major mode (for SST, this is the ENSO pattern).\n",
    "\n",
    "The term “Empirical” reflects that these patterns are derived from data, not theoretical equations — they are the data’s own preferred modes of variability.\n",
    "\n",
    "\n",
    "Each EOF is a spatial pattern (the “where” of variability), and each PC is its time series (the “when”).\n",
    "EOF1 and EOF2 are ordered by how much variance they explain — EOF1 explains the most, EOF2 the next.\n",
    "\n",
    "To visualize an eigenvector (now an EOF) as a map again, we need to reshape it back from this flattened 1-D form into its original 2-D grid shape (Ny × Nx):\n",
    "\n",
    "For example, in the code below\n",
    "```python\n",
    "EOF1 = np.real(eigvecs[:, 0]).reshape(Ny, Nx)\n",
    "```\n",
    "- `eigvecs[:, 0]` → takes the first eigenvector (corresponding to EOF 1)\n",
    "\n",
    "- `.reshape(Ny, Nx)` → restores its 2-D structure so we can plot it on latitude–longitude coordinates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8c650-60e2-44e6-9f79-f7a559ee1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract first two EOF spatial patterns (eigenvectors reshaped to lat-lon grid) ---\n",
    "EOF1 = np.real(eigvecs[:, 0]).reshape(Ny, Nx)\n",
    "EOF2 = np.real(eigvecs[:, 1]).reshape(Ny, Nx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3eebb-a8f8-448a-adb0-fb8a4c5d4102",
   "metadata": {},
   "source": [
    "After extracting the EOFs (the spatial patterns), we can find the corresponding Principal Components (PCs), the time series that tell us how strongly each pattern is expressed at each time step.\n",
    "\n",
    "Mathematically, this is done using the dot product:\n",
    "\n",
    "```python\n",
    "PC1 = np.dot(A, np.real(eigvecs[:, 0]))\n",
    "```\n",
    "\n",
    "The dot product multiplies each grid point’s SST anomaly by its weight from the EOF pattern, then sums over all grid points. In other words, it projects the full SST field at each time step onto the EOF — telling us *“how much of that spatial pattern is present in the data at that moment.\"*\n",
    "\n",
    "- `A` → SST anomaly data flattened into (time × space) form\n",
    "- `eigvecs[:, 0]` → EOF 1 (spatial weights for each grid point)\n",
    "- `np.dot(A, eigvecs[:, 0])` → multiplies each SST field by its weights → gives one value per time step (the PC time series)\n",
    "\n",
    "Thus, the dot product converts spatial information (EOF) into temporal behavior (PC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c0d69-4458-4b06-b08a-c8c89c6c8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute corresponding principal component (PC) time series ---\n",
    "PC1 = np.dot(A, np.real(eigvecs[:, 0]))\n",
    "PC2 = np.dot(A, np.real(eigvecs[:, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dc4ea2-79dd-4bf4-bc07-d8ec51596ca4",
   "metadata": {},
   "source": [
    "After computing each Principal Component (PC) time series, we standardize them so they have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "This step removes any offset or scale differences between components, making them directly comparable in amplitude and variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b6457-7795-45ff-b521-60d3ce928d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standardize the PCs to zero mean and unit variance ---\n",
    "PC1 = (PC1 - PC1.mean()) / PC1.std()\n",
    "PC2 = (PC2 - PC2.mean()) / PC2.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50602425-4b8f-4aa6-ac64-2e5df3cc64a2",
   "metadata": {},
   "source": [
    "#### Step 7. Plot EOF1 and PC1 (Seasonal Cycle mode)\n",
    "- EOF 1 shows north–south temperature contrast: warm Southern Hemisphere vs cool Northern Hemisphere.\n",
    "- PC 1 oscillates annually → this is the seasonal cycle emerging purely from statistics.\n",
    "- PCA has identified the largest repeating pattern in the data — the annual temperature swing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb8735-8085-4406-ae0a-64dd70d4b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "# EOF 1 spatial pattern\n",
    "plt.subplot(2,1,1)\n",
    "plt.pcolormesh(a.lon, a.lat, EOF1, cmap=\"RdBu_r\", vmin=-0.05, vmax=0.05)\n",
    "plt.colorbar(label=\"Amplitude\")\n",
    "plt.title(\"EOF 1: Spatial Pattern (Seasonal Cycle)\")\n",
    "\n",
    "# PC 1 time series\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(PC1, color=\"r\")\n",
    "plt.title(\"PC 1: Time Series of Seasonal Cycle Mode\")\n",
    "plt.xlabel(\"Time (months)\")\n",
    "plt.ylabel(\"Standardized Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b6a343-a3ea-4d7c-99e2-f101f07e5d6c",
   "metadata": {},
   "source": [
    "#### Step 8. Plot EOF 2 and PC 2 (ENSO / El Niño–La Niña Mode)\n",
    "- EOF 2 shows the El Niño pattern —  warm anomalies in the central/eastern Pacific, cool anomalies in the west.\n",
    "- PC 2 behaves similarly to the Niño 3.4 index (ENSO time series).\n",
    "- Positive PC 2 → El Niño; Negative PC 2 → La Niña.\n",
    "- PCA “discovered” ENSO without being told about it — that’s the power of statistical decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c44110-6c87-427d-a866-41b5339ed57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "# EOF 2 spatial pattern\n",
    "plt.subplot(2,1,1)\n",
    "plt.pcolormesh(a.lon, a.lat, EOF2, cmap=\"RdBu_r\", vmin=-0.05, vmax=0.05)\n",
    "plt.colorbar(label=\"Amplitude\")\n",
    "plt.title(\"EOF 2: Spatial Pattern (ENSO Mode)\")\n",
    "\n",
    "# PC 2 time series\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(PC2, color=\"b\")\n",
    "plt.title(\"PC 2: Time Series of ENSO Mode\")\n",
    "plt.xlabel(\"Time (months)\")\n",
    "plt.ylabel(\"Standardized Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275df24-1e36-47f0-8c46-0e3d59227147",
   "metadata": {},
   "source": [
    "#### Step 9 - Interpreting and Adjusting the Sign of EOFs\n",
    "\n",
    "When performing Principal Component Analysis (PCA) or Empirical Orthogonal Function (EOF) analysis,\n",
    "the resulting spatial patterns (EOFs) and corresponding time series (PCs) are unique only up to a sign.\n",
    "\n",
    "Mathematically, both of these are valid solutions: (EOF,PC) and (−EOF,−PC)\n",
    "\n",
    "This means that sometimes your EOF 2 map might appear “flipped” — for example, mostly blue when you expected red — because PCA does not assign physical meaning to “positive” or “negative”.\n",
    "\n",
    "What matters are:\n",
    "- the pattern of variability (warm vs. cool regions), and\n",
    "- how that pattern co-varies with its time series.\n",
    "\n",
    "To make the EOF interpretation consistent with known climate indices (e.g., Niño 3.4),\n",
    "we usually flip the sign so that positive PC values correspond to El Niño (warm eastern Pacific)\n",
    "and negative PC values correspond to La Niña (cool eastern Pacific).\n",
    "\n",
    "Because PCA’s sign is arbitrary, we compare PC2 with the Niño 3.4 index and flip the sign if they’re anticorrelated (i.e. if they're inverted).\n",
    "Here we used the overlapping 1950–2020 period, dropped missing values, and ensured both arrays had the same length before computing the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaca9f0-626b-487f-9429-99d6c4f3e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "# EOF 2 spatial pattern\n",
    "plt.subplot(2,1,1)\n",
    "# Take note of the negative sign before EOF2\n",
    "plt.pcolormesh(a.lon, a.lat, -EOF2, cmap=\"RdBu_r\", vmin=-0.05, vmax=0.05)\n",
    "plt.colorbar(label=\"Amplitude\")\n",
    "plt.title(\"EOF 2: Spatial Pattern (ENSO Mode)\")\n",
    "\n",
    "# PC 2 time series\n",
    "plt.subplot(2,1,2)\n",
    "# Take note of the negative sign before PC2\n",
    "plt.plot(-PC2, color=\"b\")\n",
    "plt.title(\"PC 2: Time Series of ENSO Mode\")\n",
    "plt.xlabel(\"Time (months)\")\n",
    "plt.ylabel(\"Standardized Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee2065-f492-41f6-b8d9-64c4a4affc20",
   "metadata": {},
   "source": [
    "#### Step 10 - Comparing the PCA-Derived ENSO Mode with the Niño 3.4 Index\n",
    "\n",
    "In the final step, we compare the second principal component (PC2) from our EOF analysis with the Niño 3.4 Index that we computed earlier from the SST anomalies.\n",
    "\n",
    "Both describe the same underlying phenomenon — the El Niño–Southern Oscillation (ENSO) — but they are derived in very different ways:\n",
    "\n",
    "- Niño 3.4 Index: a regional average of SST anomalies within 5° S–5° N and 170° W–120° W It’s a physically defined measure based on a fixed geographic box.\n",
    "- PC 2: a statistical mode obtained through Principal Component Analysis of the entire tropical Pacific SST field. PCA identifies patterns that explain the largest fractions of variance, without any prior knowledge of ENSO.\n",
    "\n",
    "By aligning their time periods and flipping the EOF 2/PC2 signs if needed, we find that these two time series are strongly correlated (typically r ≈ 0.7–0.9).\n",
    "\n",
    "This strong agreement shows that PCA objectively “rediscovers” ENSO as the second dominant mode of tropical Pacific variability, right after the seasonal cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd60526-8ee4-4e59-94fa-5a54e56c611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the sign of PC2\n",
    "PC2_fl = -PC2\n",
    "\n",
    "# Select overlapping period\n",
    "nino34_sub = nino34_std.sel(time=slice(\"1950\", \"2020\"))\n",
    "\n",
    "# Drop NaNs (from running mean)\n",
    "nino34_sub = nino34_sub.dropna(\"time\")\n",
    "\n",
    "# Match lengths\n",
    "minlen = min(len(PC2_fl), len(nino34_sub))\n",
    "pc2_aligned = PC2_fl[:minlen]\n",
    "nino34_aligned = nino34_sub.values[:minlen]\n",
    "time_aligned = nino34_sub.time[:minlen]\n",
    "\n",
    "corr = np.corrcoef(pc2_aligned, nino34_aligned)[0, 1]\n",
    "print(f\"Correlation between Niño 3.4 index and PC 2 = {corr:.2f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(time_aligned, nino34_aligned, color=\"r\", label=\"Niño 3.4 Index\")\n",
    "plt.plot(time_aligned, pc2_aligned, color=\"b\", label=\"PC 2 (EOF ENSO Mode)\")\n",
    "plt.axhline(0, color=\"gray\", lw=0.8)\n",
    "plt.legend()\n",
    "plt.title(f\"Niño 3.4 vs PCA-Derived PC 2 (1950–2020)  —  r = {corr:.2f}\")\n",
    "plt.ylabel(\"Standardized Anomaly (σ)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509e761-a0c4-472a-bc2e-eae49aae1684",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrapping Up\n",
    "\n",
    "In this lesson, we explored how Principal Component Analysis (PCA) (also known in meteorology as Empirical Orthogonal Function (EOF) analysis) can extract dominant patterns of variability from large, gridded climate datasets.\n",
    "\n",
    "We began by:\n",
    "1. Computing SST anomalies relative to a climatology.\n",
    "\n",
    "2. Deriving the Niño 3.4 Index from a fixed tropical Pacific region.\n",
    "\n",
    "3. Applying PCA to the full tropical Pacific SST field (1950 – 2020).\n",
    "\n",
    "Our results showed that:\n",
    "\n",
    "1. EOF 1 / PC 1 captures the annual (seasonal) cycle, which dominates total variance.\n",
    "2. EOF 2 / PC 2 represents the El Niño–Southern Oscillation (ENSO) pattern—warm anomalies in the central and eastern Pacific (El Niño) and cool anomalies (La Niña).\n",
    "\n",
    "After aligning signs, PC 2 strongly correlates with the Niño 3.4 Index (r ≈ 0.7–0.9), demonstrating that PCA statistically rediscovers ENSO without prior geographic constraints.\n",
    "\n",
    "Key insight:\n",
    "1. PCA identifies where and how the system varies together.\n",
    "2. It transforms high-dimensional SST data into a few meaningful spatial modes and their corresponding temporal behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc6258-aa41-4d39-ace9-121895cbb3e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### PCA and FFT\n",
    "\n",
    "Both PCA and FFT are decomposition techniques—but they answer different scientific questions.\n",
    "\n",
    "| Feature             | **PCA / EOF Analysis**                                     | **FFT / Spectral Analysis**                            |\n",
    "| ------------------- | ---------------------------------------------------------- | ------------------------------------------------------ |\n",
    "| **Goal**            | Find dominant *spatial* or *covariance* patterns           | Find dominant *temporal* frequencies                   |\n",
    "| **Basis functions** | Data-derived empirical patterns (EOFs)                     | Fixed sine + cosine waves                              |\n",
    "| **Input**           | Multivariate fields (lat × lon × time)                     | Single or multivariate time series                     |\n",
    "| **Output**          | EOFs → spatial modes; PCs → time series                    | Amplitude & phase spectra vs. frequency                |\n",
    "| **Assumptions**     | No assumption of periodicity; patterns emerge from data    | Assumes stationarity and periodicity                   |\n",
    "| **Best for**        | Discovering climate modes (ENSO, NAO, monsoon variability) | Detecting cycles (annual, diurnal, 3-7 yr ENSO period) |\n",
    "\n",
    "In essence:\n",
    "\n",
    "- PCA decomposes variance in space + time.\n",
    "- FFT decomposes variance in time + frequency.\n",
    "\n",
    "Together, they complement each other:\n",
    "PCA tells us what spatial patterns vary together, while FFT tells us how often those variations occur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (meteo203)",
   "language": "python",
   "name": "meteo203"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
